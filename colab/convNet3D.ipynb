{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "convNet3D.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mnansary/pyF2O/blob/master/colab_gen_unet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1ojVYZ7Spzpv"
      },
      "source": [
        "# colab specific task\n",
        "*   mount google drive\n",
        "*   TPU check\n",
        "*   Check TF version\n",
        "*   Change to git repo "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsY7_mMwWC3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "--q4JaV2ps6z",
        "outputId": "753972f4-bca1-4a2d-9601-4e9efb6bedf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9NVN35lELc_p",
        "outputId": "28edea98-b774-4015-b0b8-a4684be2095f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "\n",
        "# tpu check\n",
        "import os\n",
        "import pprint\n",
        "import tensorflow as tf\n",
        "if 'COLAB_TPU_ADDR' not in os.environ:\n",
        "  print('ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!')\n",
        "else:\n",
        "  TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "  print ('TPU address is', TPU_ADDRESS)\n",
        "\n",
        "  with tf.Session(TPU_ADDRESS) as session:\n",
        "    devices = session.list_devices()\n",
        "    \n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(devices)\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TPU address is grpc://10.53.190.234:8470\n",
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 6228487531686393789),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 7530780843371562102),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 18156448597659050412),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 15532005598923809813),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 6061655270171357145),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 17848330891640839161),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 11052733503231459291),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 6169043040051159501),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 15684053147171938058),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 14686118633016458763),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 12488826851948380500)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.15.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ySSaUDNQgwBK",
        "outputId": "c516c631-b676-425e-85cd-c3306a74841d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/gdrive/My\\ Drive/PROJECTS/HACT/pyACTRECOG/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/PROJECTS/HACT/pyACTRECOG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gqGOIRmujw5",
        "colab_type": "text"
      },
      "source": [
        "# GCS specific task \n",
        "* **auth user**\n",
        "* **save** and **upload** credentials to **tpu**\n",
        "* set project information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zBp1CZeupWY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# auth user for cloud SDK\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbLxepOqurpI",
        "colab_type": "code",
        "outputId": "f0a4fd81-f9b2-4d04-8c9a-e07a7a6938bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "# Save credentials\n",
        "import json\n",
        "SERVICE_KEY_PATH='/content/adc.json' # @param\n",
        "# Upload credentials to TPU.\n",
        "with tf.Session(TPU_ADDRESS) as sess:    \n",
        "    with open(SERVICE_KEY_PATH, 'r') as f:\n",
        "        auth_info = json.load(f)\n",
        "        tf.contrib.cloud.configure_gcs(sess, credentials=auth_info)\n",
        "# set service_account\n",
        "JSON_DATA=json.load(open(SERVICE_KEY_PATH))\n",
        "SERVICE_ACCOUNT=str(JSON_DATA['client_id']).split('.')[0]\n",
        "print('Service Account:',SERVICE_ACCOUNT)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "Service Account: 32555940559\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUUry52GuuzY",
        "colab_type": "text"
      },
      "source": [
        "#### SET PROJECT INFORMATION "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LQRPfsCuxl-",
        "colab_type": "code",
        "outputId": "516b8973-94a8-4533-8792-d2712c11635b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "PROJECT_ID    ='record-1106154'     # @param \n",
        "BUCKET        ='tfalldata'          # @param \n",
        "TFIDEN        ='TFRECORD'            # @param\n",
        "# LIST FILES\n",
        "TFRECORDS_DIR= 'gs://{}/{}/'.format(BUCKET,TFIDEN)\n",
        "!gcloud config set project {PROJECT_ID}\n",
        "!gsutil ls {TFRECORDS_DIR}\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n",
            "gs://tfalldata/TFRECORD/Eval/\n",
            "gs://tfalldata/TFRECORD/Train/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dxefiHZ4qlHA"
      },
      "source": [
        "# ConvNet3D Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "blwtSzOarVYM"
      },
      "source": [
        "#### Data \n",
        "* Set **FLAGS** and **PARAMS**\n",
        "* Create **Train** and **Eval** Data Generator\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BOro7D1krWYf",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('.')\n",
        "import numpy as np \n",
        "\n",
        "class FLAGS:\n",
        "    BATCH_SIZE      = 32  #@param\n",
        "    IMAGE_DIM       = 64   #@param\n",
        "    NB_CHANNELS     = 3    #@param\n",
        "    MIN_SEQ_LEN     = 6    #@param\n",
        "    NB_CLASSES      = 17   #@param\n",
        "    SHUFFLE_BUFFER  = 100 #@param\n",
        "\n",
        "MODEL_DIR           = '/content/gdrive/My Drive/PROJECTS/HACT/Model/' # @param\n",
        "MODEL_NAME          = 'convNet3D' # @param\n",
        "EPOCHS              =  250           # @param\n",
        "NB_TRAIN_DATA       =  49920       # @param\n",
        "NB_EVAL_DATA        =  3456        # @param\n",
        "NB_TOTAL_DATA       =  NB_TRAIN_DATA + NB_EVAL_DATA \n",
        "STEPS_PER_EPOCH     =  NB_TOTAL_DATA // FLAGS.BATCH_SIZE \n",
        "VALIDATION_STEPS    =  NB_EVAL_DATA  // FLAGS.BATCH_SIZE \n",
        "CHECK_DATA          =  False\n",
        "LEARNING_RATE       = 1e-4 #@param\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1guqi_rau5kA",
        "colab_type": "text"
      },
      "source": [
        "#### Data Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQy7N0hEu8D5",
        "colab_type": "code",
        "outputId": "ed6b46ea-93d8-49d7-f519-83c06158923f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.cloud import storage\n",
        "from functools import partial\n",
        "\n",
        "client = storage.Client(PROJECT_ID)\n",
        "# get bucket from the project\n",
        "bucket=client.get_bucket(BUCKET)\n",
        "print(bucket)\n",
        "\n",
        "def data_input_fn(FLAGS,mode): \n",
        "    \n",
        "    def _parser(example):\n",
        "      data  ={ 'feats':tf.io.FixedLenFeature((FLAGS.MIN_SEQ_LEN,FLAGS.IMAGE_DIM,FLAGS.IMAGE_DIM,FLAGS.NB_CHANNELS),tf.float32),\n",
        "                'label':tf.io.FixedLenFeature((),tf.int64)\n",
        "      }    \n",
        "      \n",
        "      parsed_example=tf.io.parse_single_example(example,data)\n",
        "      \n",
        "      feats=tf.cast(parsed_example['feats'],tf.float32)\n",
        "      feats=tf.reshape(feats,(FLAGS.MIN_SEQ_LEN,FLAGS.IMAGE_DIM,FLAGS.IMAGE_DIM,FLAGS.NB_CHANNELS))\n",
        "      \n",
        "      idx = tf.cast(parsed_example['label'], tf.int64)\n",
        "      label=tf.one_hot(idx,FLAGS.NB_CLASSES,dtype=tf.int64)\n",
        "      \n",
        "      return feats,label\n",
        "\n",
        "    dataset = tf.data.TFRecordDataset([os.path.join('gs://{}/'.format(BUCKET), f.name) for f in bucket.list_blobs(prefix='{}/{}'.format(TFIDEN,mode))])\n",
        "    dataset = dataset.cache()\n",
        "    dataset = dataset.map(_parser)\n",
        "    dataset = dataset.shuffle(FLAGS.SHUFFLE_BUFFER,reshuffle_each_iteration=True)\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.batch(FLAGS.BATCH_SIZE,drop_remainder=True)\n",
        "    dataset = dataset.prefetch(-1) # autotune    \n",
        "    return dataset\n",
        "\n",
        "def train_in_fn():\n",
        "    '''\n",
        "    dataset=data_input_fn(FLAGS,'Train')\n",
        "    iterator = dataset.make_one_shot_iterator()\n",
        "    X, y = iterator.get_next()\n",
        "    while True:\n",
        "        with tf.Session() as sess:\n",
        "            feats=X.eval()\n",
        "            label=y.eval()\n",
        "        yield feats,label\n",
        "    '''\n",
        "    return data_input_fn(FLAGS,'Train')    \n",
        "\n",
        "def eval_in_fn():\n",
        "    '''\n",
        "    dataset=data_input_fn(FLAGS,'Eval')\n",
        "    iterator = dataset.make_one_shot_iterator()\n",
        "    X, y = iterator.get_next()\n",
        "    while True:\n",
        "        with tf.Session() as sess:\n",
        "            feats=X.eval()\n",
        "            label=y.eval()\n",
        "        yield feats,label\n",
        "    '''    \n",
        "    return data_input_fn(FLAGS,'Eval')\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Bucket: tfalldata>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XMWNlaqLNIPY"
      },
      "source": [
        "#### COMPILE MODEL\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_WMdSlCZJPWi",
        "outputId": "3446b9bd-4bfe-4436-9fe9-470c05367220",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import sys\n",
        "sys.path.append('.')\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from coreLib.model import convNet3D\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "'''\n",
        "TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "cluster_resolver=tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)\n",
        "strategy=tf.contrib.tpu.TPUDistributionStrategy(cluster_resolver)\n",
        "#model.load_weights=os.path.join(MODEL_DIR,'{}.h5'.format(MODEL_NAME))\n",
        "#model = tf.contrib.tpu.keras_to_tpu_model(model,strategy=strategy)\n",
        "'''\n",
        "resolver = tf.contrib.cluster_resolver.TPUClusterResolver('grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "tf.contrib.distribute.initialize_tpu_system(resolver)\n",
        "strategy = tf.contrib.distribute.TPUStrategy(resolver)\n",
        "with strategy.scope():\n",
        "  model=convNet3D(seq_len=FLAGS.MIN_SEQ_LEN,\n",
        "                  img_dim=FLAGS.IMAGE_DIM,\n",
        "                  nb_channels=FLAGS.NB_CHANNELS,\n",
        "                  nb_classes=FLAGS.NB_CLASSES)\n",
        "  model.summary()\n",
        "  model.compile(optimizer=Adam(),  #tf.train.AdamOptimizer(learning_rate=LEARNING_RATE), \n",
        "                loss=categorical_crossentropy,\n",
        "                metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: 10.53.190.234:8470\n",
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.53.190.234:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 6228487531686393789)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 18156448597659050412)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 15532005598923809813)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 6061655270171357145)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 17848330891640839161)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 11052733503231459291)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 6169043040051159501)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 15684053147171938058)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 14686118633016458763)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 12488826851948380500)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 7530780843371562102)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 6, 64, 64, 3)]    0         \n",
            "_________________________________________________________________\n",
            "INITIAL_CONV3D (Conv3D)      (None, 6, 64, 64, 64)     5248      \n",
            "_________________________________________________________________\n",
            "INITIAL_POOL3D (MaxPooling3D (None, 6, 32, 32, 64)     0         \n",
            "_________________________________________________________________\n",
            "CONV3D_1_C1 (Conv3D)         (None, 6, 32, 32, 128)    221312    \n",
            "_________________________________________________________________\n",
            "POOL3D_1 (MaxPooling3D)      (None, 6, 16, 16, 128)    0         \n",
            "_________________________________________________________________\n",
            "CONV3D_2_C1 (Conv3D)         (None, 6, 16, 16, 256)    884992    \n",
            "_________________________________________________________________\n",
            "CONV3D_2_c2 (Conv3D)         (None, 6, 16, 16, 256)    1769728   \n",
            "_________________________________________________________________\n",
            "POOL3D_2 (MaxPooling3D)      (None, 6, 8, 8, 256)      0         \n",
            "_________________________________________________________________\n",
            "CONV3D_3_C1 (Conv3D)         (None, 6, 8, 8, 512)      3539456   \n",
            "_________________________________________________________________\n",
            "CONV3D_3_c2 (Conv3D)         (None, 6, 8, 8, 512)      7078400   \n",
            "_________________________________________________________________\n",
            "POOL3D_3 (MaxPooling3D)      (None, 6, 4, 4, 512)      0         \n",
            "_________________________________________________________________\n",
            "CONV3D_4_C1 (Conv3D)         (None, 6, 4, 4, 512)      7078400   \n",
            "_________________________________________________________________\n",
            "CONV3D_4_c2 (Conv3D)         (None, 6, 4, 4, 512)      7078400   \n",
            "_________________________________________________________________\n",
            "ZERO_PAD_LAST_CONV (ZeroPadd (None, 6, 6, 6, 512)      0         \n",
            "_________________________________________________________________\n",
            "POOL3D_4 (MaxPooling3D)      (None, 6, 3, 3, 512)      0         \n",
            "_________________________________________________________________\n",
            "FLATTEN (Flatten)            (None, 27648)             0         \n",
            "_________________________________________________________________\n",
            "DENSE_1 (Dense)              (None, 4096)              113250304 \n",
            "_________________________________________________________________\n",
            "DROP_1 (Dropout)             (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "DENSE_2 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "DROP_2 (Dropout)             (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "DENSE_CLASS (Dense)          (None, 17)                69649     \n",
            "=================================================================\n",
            "Total params: 157,757,201\n",
            "Trainable params: 157,757,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9nQXx8YRNSyr"
      },
      "source": [
        "#### Train\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OWTUQlweNYYN",
        "outputId": "09047fab-e159-453a-a112-e4ce703f997d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "checkpoint = ModelCheckpoint(filepath=os.path.join(MODEL_DIR,'{}.h5'.format(MODEL_NAME)), verbose=1, save_best_only=True)\n",
        "history=model.fit(train_in_fn(), #_generator\n",
        "                    epochs= EPOCHS,\n",
        "                    steps_per_epoch=STEPS_PER_EPOCH, \n",
        "                    validation_data=eval_in_fn(),\n",
        "                    validation_steps=VALIDATION_STEPS,\n",
        "                    callbacks=[checkpoint],\n",
        "                    verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "1265/1668 [=====================>........] - ETA: 52s - loss: 2.8306 - acc: 0.0802"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Or0XpoYadSF7",
        "colab_type": "text"
      },
      "source": [
        "#### Save Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFDwgbUVdSwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights(os.path.join(MODEL_DIR,'{}_final.h5'.format(MODEL_NAME)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J1M9sjHIbSnf"
      },
      "source": [
        "#### Plot Training Histoty"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ndNSS7XIbXaK",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('LOSS History')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.savefig(os.path.join(MODEL_DIR,'{}_history.png'.format(MODEL_NAME)))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}